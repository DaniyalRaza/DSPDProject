{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IVAvHY4_BAh",
    "outputId": "feda2940-5a48-4d79-92b4-88462799b867"
   },
   "outputs": [],
   "source": [
    "!pip3 install scikit-image\n",
    "!pip3 install nose\n",
    "!pip3 install tornado\n",
    "!pip3 install keras\n",
    "!pip3 install keras_vggface\n",
    "!pip3 install pandas\n",
    "!pip3 install h5py\n",
    "!pip3 install keras_applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWiP2amZ_BAh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from tensorflow.keras import utils\n",
    "from skimage.transform import resize\n",
    "from keras import backend as K\n",
    "from keras import utils as np_utils\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, Callback, ModelCheckpoint\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxOjEV7s_BAi"
   },
   "outputs": [],
   "source": [
    "folder = './'\n",
    "\n",
    "img_height, img_width = 197, 197\n",
    "\n",
    "num_classes         = 7   # ['Anger', 'Disgust', 'Fear', 'Happiness', 'Sadness', 'Surprise', 'Neutral']\n",
    "epochs_top_layers   = 5\n",
    "epochs_all_layers   = 100\n",
    "batch_size          = 128\n",
    "\n",
    "train_dataset\t= 'train.csv'\n",
    "eval_dataset \t= 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geqYwa2q_BAj"
   },
   "outputs": [],
   "source": [
    "base_model = VGGFace(\n",
    "    model       = 'resnet50',\n",
    "    include_top = False,\n",
    "    weights     = 'vggface',\n",
    "    input_shape = (img_height, img_width, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "\n",
    "predictions = Dense(num_classes, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "cjCh5s4u_BAj",
    "outputId": "15d3ec61-d611-4bb0-aec3-793b1a501a5c"
   },
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x -= 128.8006 # np.mean(train_dataset)\n",
    "    return x\n",
    "\n",
    "def get_data(dataset):\n",
    "    file_stream = file_io.FileIO(dataset, mode='r')\n",
    "    data = pd.read_csv(file_stream)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    images = np.empty((len(data), img_height, img_width, 3))\n",
    "    i = 0\n",
    "\n",
    "    for pixel_sequence in pixels:\n",
    "        single_image = [float(pixel) for pixel in pixel_sequence.split(' ')]  # Extraction of each single\n",
    "        single_image = np.asarray(single_image).reshape(48, 48) # Dimension: 48x48\n",
    "        single_image = resize(single_image, (img_height, img_width), order = 3, mode = 'constant') # Dimension: 139x139x3\n",
    "        ret = np.empty((img_height, img_width, 3))  \n",
    "        ret[:, :, 0] = single_image\n",
    "        ret[:, :, 1] = single_image\n",
    "        ret[:, :, 2] = single_image\n",
    "        images[i, :, :, :] = ret\n",
    "        i += 1\n",
    "    \n",
    "    images = preprocess_input(images)\n",
    "    labels = utils.to_categorical(data['emotion'])\n",
    "\n",
    "    return images, labels    \n",
    "\n",
    "train_data_x, train_data_y  = get_data(train_dataset)\n",
    "val_data  = get_data(eval_dataset)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range  = 10,\n",
    "    shear_range     = 10, # 10 degrees\n",
    "    zoom_range      = 0.1,\n",
    "    fill_mode       = 'reflect',\n",
    "    horizontal_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow(\n",
    "    train_data_x,\n",
    "    train_data_y,\n",
    "    batch_size  = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMyxlLbC_BAl"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer   = Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0), \n",
    "    loss        = 'categorical_crossentropy', \n",
    "    metrics     = ['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "    generator           = train_generator,\n",
    "    steps_per_epoch     = len(train_data_x) // batch_size,  # samples_per_epoch / batch_size\n",
    "    epochs              = epochs_top_layers,                            \n",
    "    validation_data     = val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5ZkdL5f_BAm"
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=SGD(lr=1e-4, momentum=0.9, decay=0.0, nesterov=True),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "def scheduler(epoch):\n",
    "    updated_lr = K.get_value(model.optimizer.lr) * 0.5\n",
    "    if (epoch % 3 == 0) and (epoch != 0):\n",
    "        K.set_value(model.optimizer.lr, updated_lr)\n",
    "        print(K.get_value(model.optimizer.lr))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "\n",
    "reduce_lr_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    mode='auto',\n",
    "    min_lr=1e-8)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='auto')\n",
    "\n",
    "check_point = ModelCheckpoint(\"model_weights.h5\",\n",
    "                              monitor='val_loss',\n",
    "                              verbose=1,\n",
    "                              save_best_only=True,\n",
    "                              mode='auto')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=len(train_data_x) // batch_size,\n",
    "    epochs=epochs_all_layers,\n",
    "    validation_data=val_data,\n",
    "    callbacks=[reduce_lr, reduce_lr_plateau, early_stop, check_point])\n",
    "\n",
    "model.save(folder + 'ResNet-50.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNet-50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
